Basic XOR test of the good/bad nn trainer
=========================================


Introduction
------------

The premise here is pretty simple. Instead of defining a set of
"correct" input/output pairs for training, we create a set of "opposite"
outputs and use "good/bad" to trigger learning. If performing an output
is "good" then the network is trained with the output it just performed.
If performing an output is "bad" the network is trained with the
opposite to the output.


In action
---------

Firstly, we need a neural network to calculate the XOR function

    >>> import libs.nn.backpropnn
    >>> nn = libs.nn.backpropnn.NN(2, 2, 1)

Now we need a trainer

    >>> import trainer
    >>> t = trainer.Trainer(nn, 10, (), 0)

This neural network doesn't do XOR correctly, so lets train it. Firstly
we train on 0, 0 and show the memory as we go.

    >>> input = (0, 0)
    >>> t.getoutput(input)
    (0,)

    >>> t.good()
    >>> t.memory
    deque([((0, 0), (0,))], maxlen=10)

    >>> t.getoutput()
    (0,)

Then on 0, 1

    >>> input = (0, 1)
    >>> t.getoutput(input)
    (0,)

    >>> t.bad()
    (0,)

    >>> t.bad()
    (0,)

    >>> t.bad()
    (1,)

    >>> t.good()
    >>> t.memory
    deque([((0, 0), (0,)), ((0, 1), (1,))], maxlen=10)

    >>> t.getoutput()
    (1,)

Then 1, 0

    >>> input = (1, 0)
    >>> t.getoutput(input)
    (0,)

    >>> t.bad()
    (0,)

    >>> t.bad()
    (1,)

    >>> t.good()
    >>> t.getoutput()
    (1,)

Then 1, 1

    >>> input = (1, 1)
    >>> t.getoutput(input)
    (1,)

    >>> t.bad()
    (1,)

    >>> t.bad()
    (1,)

    >>> import random
    >>> random.seed(93)

    >>> t.bad()
    (0,)

    >>> t.good()
    >>> t.memory
    deque([((0, 0), (0,)), ((0, 1), (1,)), ((1, 0), (1,)), ((1, 1), (0,))], maxlen=10)

    >>> t.getoutput()
    (0,)

Now we can test it all at once

    >>> t.getoutput((0, 0))
    (0,)

    >>> t.getoutput((0, 1))
    (1,)

    >>> t.getoutput((1, 0))
    (1,)

    >>> t.getoutput((1, 1))
    (0,)
