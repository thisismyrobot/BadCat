Basic XOR test of the good/bad nn trainer
=========================================


Introduction
------------

The premise here is pretty simple. Instead of defining a set of "correct"
input/output pairs for training, we simple let the trainer know if the result
is "good" or "bad", "bad" leading to re-training until the output is "good".

In action
---------

Firstly, we need a neural network to calculate the XOR function - 2 inputs of
range 0-1, 2 hidden neurons and 1 output neuron.

    >>> import neurolab
    >>> nn = neurolab.net.newff([[0, 1], [0, 1]],[2, 1])

Now we need a trainer

    >>> import trainer
    >>> t = trainer.Trainer(nn, 10, (), 0)

This neural network doesn't do XOR correctly, so lets train it. Firstly
we train on 0, 0 and show the memory as we go.

    >>> input = (0, 0)
    >>> _ = t.getoutput(input)

    >>> while t.bad() != (0,):
    ...     pass

    >>> t.good()
    >>> t.memory
    deque([((0, 0), (0,))], maxlen=10)

    >>> t.getoutput()
    (0,)

Then on 0, 1

    >>> input = (0, 1)
    >>> _ = t.getoutput(input)

    >>> while t.bad() != (1,):
    ...     pass

    >>> t.good()
    >>> t.memory
    deque([((0, 0), (0,)), ((0, 1), (1,))], maxlen=10)

    >>> t.getoutput()
    (1,)

Then 1, 0

    >>> input = (1, 0)
    >>> _ = t.getoutput(input)

    >>> while t.bad() != (1,):
    ...     pass

    >>> t.good()
    >>> t.getoutput()
    (1,)

Then 1, 1

    >>> input = (1, 1)
    >>> _ = t.getoutput(input)

    >>> while t.bad() != (0,):
    ...     pass

    >>> t.good()
    >>> t.memory
    deque([((0, 0), (0,)), ((0, 1), (1,)), ((1, 0), (1,)), ((1, 1), (0,))], maxlen=10)

    >>> t.getoutput()
    (0,)

Now we can test it all at once

    >>> t.getoutput((0, 0))
    (0,)

    >>> t.getoutput((0, 1))
    (1,)

    >>> t.getoutput((1, 0))
    (1,)

    >>> t.getoutput((1, 1))
    (0,)
